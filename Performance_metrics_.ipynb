{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "id": "s0Ej_bXyQvnV"
   },
   "source": [
    "# Compute performance metrics for the given Y and Y_score without sklearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "4CHb6NE7Qvnc"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "# other than these two you should not import any other packages"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "id": "KbsWXuDaQvnq"
   },
   "source": [
    "\n",
    "## A. Compute performance metrics for the given data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "WaFLW7oBQvnt"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>y</th>\n",
       "      <th>proba</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.637387</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.635165</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.766586</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.724564</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.889199</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     y     proba\n",
       "0  1.0  0.637387\n",
       "1  1.0  0.635165\n",
       "2  1.0  0.766586\n",
       "3  1.0  0.724564\n",
       "4  1.0  0.889199"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_a=pd.read_csv(r'C:\\Users\\HP\\OneDrive\\Applied ai\\Module 3\\assignment\\Performance_metrics_\\5_a.csv')\n",
    "df_a.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def confusion_matrix(df_a):\n",
    "\n",
    "    TN = df_a.loc[(df_a['y'] == 0) & (df_a['proba']< 0.5)].count()[0]\n",
    "    FN = df_a.loc[(df_a['y'] == 1) & (df_a['proba']< 0.5)].count()[0]\n",
    "\n",
    "    FP = df_a.loc[(df_a['y'] == 0) & (df_a['proba']> 0.5)].count()[0]\n",
    "    TP = df_a.loc[(df_a['y'] == 1) & (df_a['proba']> 0.5)].count()[0]\n",
    "\n",
    "    return TN, FN, FP, TP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "confusion_matrix\n",
      " [[    0     0]\n",
      " [  100 10000]]\n"
     ]
    }
   ],
   "source": [
    "TN, FN, FP, TP = confusion_matrix(df_a)\n",
    "con_matrix = np.array([[TN,FN],[FP,TP]])\n",
    "print('confusion_matrix\\n',con_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def f1_score(df_a):\n",
    "    TN, FN, FP, TP = confusion_matrix(df_a)\n",
    "    Pr = TP/(TP+FP)\n",
    "    Re = TP/(FN+TP)\n",
    "\n",
    "    f1 = 2*Pr*Re/(Pr+Re)\n",
    "    return f1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "f1_score  0.9950248756218906\n"
     ]
    }
   ],
   "source": [
    "print('f1_score ',f1_score(df_a))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "yg8uUJvGAfCM"
   },
   "outputs": [],
   "source": [
    "def auc_score(df_a):\n",
    "    a_des = df_a.sort_values(by =['proba'], ascending=False)\n",
    "\n",
    "    tpr = []\n",
    "    fpr = []\n",
    "    for t in range(0,len(a_des)):\n",
    "        \n",
    "        a_des['proba_t'] = np.where(a_des['proba']>=a_des.iloc[t]['proba'],1,0 )\n",
    "        TN = len(a_des.loc[(a_des['y'] == 0) & (a_des['proba_t'] == 0)])\n",
    "        FN = len(a_des.loc[(a_des['y'] == 1) & (a_des['proba_t']== 0)])\n",
    "\n",
    "        FP = len(a_des.loc[(a_des['y'] == 0) & (a_des['proba_t']==1)])\n",
    "        TP = len(a_des.loc[(a_des['y'] == 1) & (a_des['proba_t']== 1)])\n",
    "\n",
    "        #print(confusion_matrix)\n",
    "        tpr.append(TP/(TP+FN))\n",
    "        fpr.append(FP/(TN+FP))\n",
    "    AUC = np.trapz(np.array(tpr), np.array(fpr))\n",
    "    return AUC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AUC score  0.48829900000000004\n"
     ]
    }
   ],
   "source": [
    "print(\"AUC score \",auc_score(df_a))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def accuracy_score(df_a):\n",
    "    TN, FN, FP, TP = confusion_matrix(df_a)\n",
    "    acc_score =((TP+TN)/(TN+FN+FP+TP))\n",
    "    return acc_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy  0.9900990099009901\n"
     ]
    }
   ],
   "source": [
    "print(\"Accuracy \",accuracy_score(df_a))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "id": "V5KZem1BQvn2"
   },
   "source": [
    "\n",
    "\n",
    "## B. Compute performance metrics for the given data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "U2sKlq0YQvn5"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>y</th>\n",
       "      <th>proba</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0.281035</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0.465152</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0.352793</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0.157818</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0.276648</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   y     proba\n",
       "0  0  0.281035\n",
       "1  0  0.465152\n",
       "2  0  0.352793\n",
       "3  0  0.157818\n",
       "4  0  0.276648"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_b=pd.read_csv(r'C:\\Users\\HP\\OneDrive\\Applied ai\\Module 3\\assignment\\Performance_metrics_\\5_b.csv')\n",
    "df_b.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "xlLVa-cVAfCS"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "confusion_matrix\n",
      " [[9761   45]\n",
      " [ 239   55]]\n"
     ]
    }
   ],
   "source": [
    "TN, FN, FP, TP = confusion_matrix(df_b)\n",
    "con_matrix = np.array([[TN,FN],[FP,TP]])\n",
    "print('confusion_matrix\\n', con_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "f1_score  0.2791878172588833\n"
     ]
    }
   ],
   "source": [
    "print('f1_score ',f1_score(df_b))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AUC score  0.9377570000000001\n"
     ]
    }
   ],
   "source": [
    "print(\"AUC score \",auc_score(df_b))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy  0.9718811881188119\n"
     ]
    }
   ],
   "source": [
    "print(\"Accuracy \",accuracy_score(df_b))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "id": "GiPGonTzQvoB"
   },
   "source": [
    "### C. Compute the best threshold (similarly to ROC curve computation) of probability which gives lowest values of metric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "id": "x5HIJzq1QvoE"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>y</th>\n",
       "      <th>prob</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0.458521</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0.505037</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0.418652</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0.412057</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0.375579</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   y      prob\n",
       "0  0  0.458521\n",
       "1  0  0.505037\n",
       "2  0  0.418652\n",
       "3  0  0.412057\n",
       "4  0  0.375579"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_c=pd.read_csv(r'C:\\Users\\HP\\OneDrive\\Applied ai\\Module 3\\assignment\\Performance_metrics_\\5_c.csv')\n",
    "df_c.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "141000\n",
      "best threshold  0.230039028\n"
     ]
    }
   ],
   "source": [
    "metric_A = {}\n",
    "c_des = df_c.sort_values(by=['prob'], ascending=False)\n",
    "unique_probs = c_des['prob'].unique()\n",
    "for t in unique_probs:\n",
    "    c_des['ypred'] = np.where(c_des['prob']<t,0,1)\n",
    "    FN = len(c_des.loc[(c_des['y'] == 1) & (c_des['ypred']== 0)])\n",
    "    FP = len(c_des.loc[(c_des['y'] == 0) & (c_des['ypred']==1)])\n",
    "    A = 500*FN + 100*FP\n",
    "    metric_A[t] = A\n",
    "#print(metric_A)\n",
    "min_val = min(metric_A.values())\n",
    "print(min_val)\n",
    "\n",
    "min_val_key = [k for k in metric_A if metric_A[k] == min_val]\n",
    "best_threshold = min_val_key[0]\n",
    "print(\"best threshold \",best_threshold)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "id": "sD4CcgjXQvoL"
   },
   "source": [
    "\n",
    "## D.</b></font> Compute performance metrics(for regression) for the given data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "id": "sVOj-bF9AfCd"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>y</th>\n",
       "      <th>pred</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>101.0</td>\n",
       "      <td>100.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>120.0</td>\n",
       "      <td>100.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>131.0</td>\n",
       "      <td>113.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>164.0</td>\n",
       "      <td>125.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>154.0</td>\n",
       "      <td>152.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       y   pred\n",
       "0  101.0  100.0\n",
       "1  120.0  100.0\n",
       "2  131.0  113.0\n",
       "3  164.0  125.0\n",
       "4  154.0  152.0"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_d=pd.read_csv(r'C:\\Users\\HP\\OneDrive\\Applied ai\\Module 3\\assignment\\Performance_metrics_\\5_d.csv')\n",
    "df_d.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "id": "uRhL1pheAfCe"
   },
   "outputs": [],
   "source": [
    "error = []\n",
    "sstotal = []\n",
    "se = []\n",
    "y_mean = (df_d['y'].sum())/len(df_d)\n",
    "for i in range(len(df_d)):\n",
    "    err = (abs((df_d.iloc[i]['y']) - (df_d.iloc[i]['pred'])))\n",
    "    ss = ((df_d.iloc[i]['y']) - y_mean)\n",
    "    error.append(err)\n",
    "    sstotal.append(ss*ss)\n",
    "    se.append((err*err))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mean absolute percentage error  12.91202994009687\n",
      "Mean squared error 177.16569974554707\n",
      "R squared 0.9563582786990964\n"
     ]
    }
   ],
   "source": [
    "mape = (sum(error)/(df_d['y'].sum()))*100\n",
    "mse = sum(se)/len(df_d)\n",
    "rres = (1 - (sum(se)/sum(sstotal)))\n",
    "print('mean absolute percentage error ',mape)\n",
    "print('Mean squared error',mse )\n",
    "print('R squared',rres)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "5_Performance_metrics_Instructions.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "vscode": {
   "interpreter": {
    "hash": "dc07d24e2f18896857f0b2a651fe84ba40ce7b297e58d8804a308c8039f752a6"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
